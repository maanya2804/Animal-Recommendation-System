import streamlit as st
import numpy as np
import os
from PIL import Image
import zipfile

import faiss
from sklearn.neighbors import NearestNeighbors

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

# ==========================================
# 1Ô∏è‚É£ Streamlit Page Setup
# ==========================================
st.set_page_config(page_title="Animal Recommendation System", layout="wide")

st.title("üêæ Animal Image Recommendation System")
st.write("Upload an animal image and get recommendations using:")
st.markdown("‚úÖ KNN   ‚ö° FAISS Flat   üöÄ FAISS IVF")
st.divider()

# ==========================================
# 2Ô∏è‚É£ Kaggle Dataset Auto Download
# ==========================================
DATASET_FOLDER = "animals"

if not os.path.exists(DATASET_FOLDER):

    st.warning("Dataset not found. Downloading from Kaggle...")

    # Kaggle secrets
    os.environ["KAGGLE_USERNAME"] = st.secrets["KAGGLE_USERNAME"]
    os.environ["KAGGLE_KEY"] = st.secrets["KAGGLE_KEY"]

    # Download dataset
    os.system(
        "kaggle datasets download -d iamsouravbanerjee/animal-image-dataset-90-different-animals"
    )

    # Extract zip
    with zipfile.ZipFile(
        "animal-image-dataset-90-different-animals.zip", "r"
    ) as zip_ref:
        zip_ref.extractall("dataset")

    os.rename("dataset/animals", "animals")

    st.success("‚úÖ Dataset Downloaded Successfully!")

# ==========================================
# 3Ô∏è‚É£ Load Dataset Image Paths
# ==========================================
image_paths = []

for root, dirs, files in os.walk(DATASET_FOLDER):
    for file in files:
        if file.lower().endswith((".jpg", ".jpeg", ".png")):
            image_paths.append(os.path.join(root, file))

st.success(f"‚úÖ Total Dataset Images Found: {len(image_paths)}")

if len(image_paths) == 0:
    st.error("No images found in dataset folder!")
    st.stop()

# ==========================================
# 4Ô∏è‚É£ Load MobileNetV2 Model
# ==========================================
@st.cache_resource
def load_model():
    return MobileNetV2(weights="imagenet", include_top=False, pooling="avg")

model = load_model()

# ==========================================
# 5Ô∏è‚É£ Extract Embedding Function
# ==========================================
def extract_embedding(img):

    img = img.resize((224, 224))
    img_array = np.array(img)

    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)

    emb = model.predict(img_array, verbose=0)
    return emb.flatten()

# ==========================================
# 6Ô∏è‚É£ Load or Create Embeddings
# ==========================================
embedding_file = "animal_embeddings.npy"

if not os.path.exists(embedding_file):

    st.warning("Embeddings not found. Creating embeddings...")

    embeddings = []
    progress = st.progress(0)

    for i, img_path in enumerate(image_paths):

        img = Image.open(img_path)
        emb = extract_embedding(img)
        embeddings.append(emb)

        progress.progress((i + 1) / len(image_paths))

    embeddings = np.array(embeddings)
    np.save(embedding_file, embeddings)

    st.success("‚úÖ Embeddings Extracted and Saved!")

else:
    embeddings = np.load(embedding_file)
    st.success("‚úÖ Embeddings Loaded Successfully!")

st.write("Embeddings Shape:", embeddings.shape)

# ==========================================
# 7Ô∏è‚É£ Build Recommendation Models
# ==========================================

# ---- KNN ----
knn = NearestNeighbors(n_neighbors=5, metric="cosine")
knn.fit(embeddings)

# ---- FAISS Flat ----
dim = embeddings.shape[1]
index_flat = faiss.IndexFlatL2(dim)
index_flat.add(embeddings)

# ---- FAISS IVF ----
nlist = 50
quantizer = faiss.IndexFlatL2(dim)

index_ivf = faiss.IndexIVFFlat(quantizer, dim, nlist)
index_ivf.train(embeddings)
index_ivf.add(embeddings)

index_ivf.nprobe = 10

st.success("‚úÖ All Recommendation Models Ready!")
st.divider()

# ==========================================
# 8Ô∏è‚É£ Display Recommendation Function
# ==========================================
def show_results(title, indices):

    st.subheader(title)

    cols = st.columns(5)

    for i, idx in enumerate(indices):
        img = Image.open(image_paths[idx])
        cols[i].image(img, width=150)

# ==========================================
# 9Ô∏è‚É£ Upload Query Image
# ==========================================
uploaded_file = st.file_uploader(
    "üìå Upload Query Animal Image",
    type=["jpg", "jpeg", "png"]
)

if uploaded_file is not None:

    query_img = Image.open(uploaded_file)

    st.image(query_img, caption="üì∑ Query Image", width=250)

    query_vector = extract_embedding(query_img)

    k = 5

    # ==============================
    # KNN Recommendations
    # ==============================
    distances_knn, indices_knn = knn.kneighbors([query_vector], k)
    show_results("‚úÖ KNN Recommendations", indices_knn[0])

    # ==============================
    # FAISS Flat Recommendations
    # ==============================
    D_flat, I_flat = index_flat.search(np.array([query_vector]), k)
    show_results("‚ö° FAISS Flat Recommendations", I_flat[0])

    # ==============================
    # FAISS IVF Recommendations
    # ==============================
    D_ivf, I_ivf = index_ivf.search(np.array([query_vector]), k)
    show_results("üöÄ FAISS IVF Recommendations", I_ivf[0])
